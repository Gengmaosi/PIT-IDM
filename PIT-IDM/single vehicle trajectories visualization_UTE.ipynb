{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acceptable-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def all_step_error(outputs, labels):\n",
    "    out = ((outputs-labels)**2)**0.5\n",
    "    lossVal = torch.mean(out[:,:,0],dim=0)\n",
    "    err_mean = torch.zeros([6])\n",
    "    err_final = torch.zeros([6])\n",
    "    for i in range(6):\n",
    "        err_mean[i] = torch.mean(lossVal[:5*(i+1)])\n",
    "        err_final[i] = lossVal[5*(i+1)-1]\n",
    "    return err_mean, err_final\n",
    "\n",
    "def step_error(outputs, labels):\n",
    "    out = ((outputs-labels)**2)**0.5\n",
    "    lossVal = torch.mean(out[:,:,0],dim=0)\n",
    "    lossmean = torch.mean(lossVal)\n",
    "    lossfinal = lossVal[-1]\n",
    "    \n",
    "    return lossmean, lossfinal\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"\"\"\n",
    "    Mask out subsequent positions.\n",
    "    \"\"\"\n",
    "    attn_shape = (1, size, size)\n",
    "    mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(mask) == 0\n",
    "\n",
    "def _generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()       \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        #pe.requires_grad = False\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "def model_IDM(inputs_IDM, his_labels, output_length):\n",
    "    v_pred = torch.zeros((inputs_IDM.shape[0], output_length, 1))\n",
    "    y_pred = torch.zeros((inputs_IDM.shape[0], output_length, 1))\n",
    "    acc = torch.zeros((inputs_IDM.shape[0], output_length, 1))\n",
    "    y = inputs_IDM[:,0]\n",
    "    v = inputs_IDM[:,1]\n",
    "    s = inputs_IDM[:,2]\n",
    "    delta_v = inputs_IDM[:,3]\n",
    "        \n",
    "    s_x = s_0+ torch.max(torch.tensor(0), v*T+((v*delta_v)/(2*(a*b)**0.5)))\n",
    "    #s_x = torch.tensor(2.5)+ torch.max(torch.tensor(0), v*torch.tensor(1.25)+((v*delta_v)/(2*(torch.tensor(1.75)*torch.tensor(1.25))**0.5)))\n",
    "    a_f = a*(1-(v/v_d)**4-(s_x/s)**2)\n",
    "    #a_f = torch.tensor(1.75)*(1-(v/torch.tensor(30))**4-(s_x/s)**2)\n",
    "    v_pred[:,0,0] = v+a_f*dt\n",
    "    for i in range(len(v_pred)):\n",
    "        if v_pred[i,0,0]<=0:\n",
    "            v_pred[i,0,0]=0\n",
    "    y_pred[:,0,0] = y+v_pred[i,0,0]*dt\n",
    "    acc[:,0,0] = a_f\n",
    "        \n",
    "    for i in range(y_pred.shape[0]):\n",
    "        for j in range(output_length-1):\n",
    "            v = v_pred[i,j,0]\n",
    "            delta_v = his_labels[i,j,1]-v_pred[i,j,0]\n",
    "            s = his_labels[i,j,0]-y_pred[i,j,0]\n",
    "            #s_x = self.s_0 + self.T*v - ((v * delta_v)/(2*(self.a*self.b)**0.5))\n",
    "            #s_x = s_0 +  v*T-((v*delta_v)/(2*(a*b)**0.5))\n",
    "            s_x = s_0 +  torch.max(torch.tensor(0), v*T+((v*delta_v)/(2*(a*b)**0.5)))\n",
    "            #acc_temp = self.a*(1-(v/self.v_d)**4-(s_x/s)**2)\n",
    "            acc_temp = a*(1-(v/v_d)**4-(s_x/s)**2)\n",
    "            v2 = v + acc_temp * dt\n",
    "            if v2<=0:\n",
    "                v2 = 0\n",
    "                acc_temp = (v2-v)/dt\n",
    "            y1 = y_pred[i,j,0]\n",
    "            y2 = y1 + v2 * dt\n",
    "            acc[i,j+1,0] = acc_temp\n",
    "            v_pred[i,j+1,0] = v2\n",
    "            y_pred[i,j+1,0] = y2\n",
    "                   \n",
    "    return y_pred\n",
    "\n",
    "class IDMModel(nn.Module):\n",
    "    def __init__(self, s_0, T, a, b, v_d):\n",
    "        super(IDMModel, self).__init__()\n",
    "        self.model_type = 'IDM'\n",
    "        self.dt=0.1\n",
    "        self.s_0 = torch.tensor([1.667], requires_grad=True)\n",
    "        self.T = torch.tensor([0.504], requires_grad=True)\n",
    "        self.a = torch.tensor([0.430], requires_grad=True)\n",
    "        self.b = torch.tensor([3.216], requires_grad=True)\n",
    "        self.v_d = torch.tensor([16.775], requires_grad=True)\n",
    "        \n",
    "        self.s_0 = torch.nn.Parameter(self.s_0)\n",
    "        self.T = torch.nn.Parameter(self.T)\n",
    "        self.a = torch.nn.Parameter(self.a)\n",
    "        self.b = torch.nn.Parameter(self.b)\n",
    "        self.v_d = torch.nn.Parameter(self.v_d)\n",
    "        \n",
    "        self.s_0.data.fill_(s_0)\n",
    "        self.T.data.fill_(T)\n",
    "        self.a.data.fill_(a)\n",
    "        self.b.data.fill_(b)\n",
    "        self.v_d.data.fill_(v_d)\n",
    "    def forward(self, inputs_IDM, his_labels):\n",
    "        y = inputs_IDM[:,0]\n",
    "        v = inputs_IDM[:,1]\n",
    "        s = inputs_IDM[:,2]\n",
    "        delta_v = inputs_IDM[:,3]\n",
    "        \n",
    "        s_x = self.s_0+  v*self.T+((v*delta_v)/(2*(self.a*self.b)**0.5))\n",
    "        a_f = self.a*(1-(v/self.v_d)**4-(s_x/s)**2)\n",
    "        v_pred = v+a_f*self.dt\n",
    "        for i in range(len(v_pred)):\n",
    "            if v_pred[i]<=0:\n",
    "                v_pred[i]==0\n",
    "        output_IDM = y+v_pred*self.dt\n",
    "        return output_IDM.unsqueeze(1).unsqueeze(2), torch.Tensor(self.s_0.data.cpu().numpy()), torch.Tensor(self.T.data.cpu().numpy()), torch.Tensor(self.a.data.cpu().numpy()), torch.Tensor(self.b.data.cpu().numpy()), torch.Tensor(self.v_d.data.cpu().numpy())\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ninput, ntoken, ninp, nhead, nhid, fusion_size, nlayers, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.src_mask = None\n",
    "        self.encoder_pos = PositionalEncoding(ninp)\n",
    "        self.encoder_emb = nn.Linear(ninput, ninp)\n",
    "        self.encoder_layer = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.encoder = TransformerEncoder(self.encoder_layer, nlayers)\n",
    "        self.decoder_emb = nn.Linear(ninput, ninp)\n",
    "        self.decoder_layer = TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.decoder = TransformerDecoder(self.decoder_layer, nlayers)\n",
    "        self.output_layer = nn.Linear(ninp, ntoken)\n",
    "        self.fusion_layer = nn.Linear(fusion_size, ntoken)\n",
    "        self.init_weights()\n",
    "\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1    \n",
    "        self.encoder_emb.bias.data.zero_()\n",
    "        self.encoder_emb.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder_emb.bias.data.zero_()\n",
    "        self.decoder_emb.weight.data.uniform_(-initrange, initrange)\n",
    "        self.output_layer.bias.data.zero_()\n",
    "        self.output_layer.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fusion_layer.bias.data.zero_()\n",
    "        self.fusion_layer.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src_inputs, dec_input, target_mask, his_labels):\n",
    "        inputs = src_inputs[:,:,[0]]\n",
    "        src = self.encoder_pos(self.encoder_emb(inputs.transpose(0,1)))\n",
    "        memory = self.encoder(src)\n",
    "        inp_decoder = self.decoder_emb(dec_input.transpose(0,1))\n",
    "        out_decoder = self.decoder(inp_decoder, memory, target_mask)\n",
    "        output = self.output_layer(out_decoder)\n",
    "        output = output.transpose(0,1)\n",
    "        dv = (inputs[:,-1,0]-inputs[:,-2,0])/1\n",
    "        hist = torch.zeros(output.shape)\n",
    "        for i in range(hist.shape[0]):\n",
    "            hist[i,:,0] = torch.linspace(inputs[i,-1,0].item(), inputs[i,-1,0].item()+dv[i].item()*output.shape[1], output.shape[1]+1)[1:]\n",
    "        out_length = output.shape[1]\n",
    "        output_IDM = model_IDM(src_inputs[:,-1,:], his_labels[:,:out_length,:], out_length)\n",
    "        fusion = torch.cat([output, hist, output_IDM], axis=2)\n",
    "        final_output = self.fusion_layer(fusion)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pacific-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, s_0, T, a, b, v_d, ninput, ntoken, ninp, nhead, nhid, fusion_size, nlayers, dropout):\n",
    "        super(PINN, self).__init__()\n",
    "        self.dt = 0.1\n",
    "        self.output_length = 30\n",
    "        #self.s_0 = torch.tensor(s_0, requires_grad=True)\n",
    "        #self.T = torch.tensor(T, requires_grad=True)\n",
    "        #self.a = torch.tensor(a, requires_grad=True)\n",
    "        #self.b = torch.tensor(b, requires_grad=True)\n",
    "        #self.v_d = torch.tensor(v_d, requires_grad=True)\n",
    "        \n",
    "        #self.s_0 = torch.nn.Parameter(self.s_0)\n",
    "        #self.T = torch.nn.Parameter(self.T)\n",
    "        #self.a = torch.nn.Parameter(self.a)\n",
    "        #self.b = torch.nn.Parameter(self.b)\n",
    "        #self.v_d = torch.nn.Parameter(self.v_d)\n",
    "        \n",
    "        self.PUNN = TransformerModel(ninput, ntoken, ninp, nhead, nhid, fusion_size, nlayers, dropout)\n",
    "        self.PINN = IDMModel(s_0, T, a, b, v_d)\n",
    "        \n",
    "        #self.Transformer.register_parameter('s_0', self.s_0)\n",
    "        #self.Transformer.register_parameter('T', self.T)\n",
    "        #self.Transformer.register_parameter('a', self.a)\n",
    "        #self.Transformer.register_parameter('b', self.b)\n",
    "        #self.Transformer.register_parameter('v_d', self.v_d)\n",
    "        \n",
    "        #self.optimizer = torch.optim.Adam(self.Transformer.parameters(), lr=0.00005)\n",
    "        self.optimizer = torch.optim.Adam([{'params':self.PUNN.parameters(), 'lr':0.0005},{'params':self.PINN.parameters(),'lr':0.0000001}])\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, 15, gamma=0.1)\n",
    "        #self.optimizer_PUNN = torch.optim.Adam(self.PUNN.parameters(), lr=0.0005)\n",
    "        #self.scheduler_PUNN = torch.optim.lr_scheduler.StepLR(self.optimizer_PUNN, 15, gamma=0.1)\n",
    "        #self.optimizer_PINN = torch.optim.Adam(self.PINN.parameters(), lr=0.0005)\n",
    "        #self.scheduler_PINN = torch.optim.lr_scheduler.StepLR(self.optimizer_PINN, 15, gamma=0.1)\n",
    "        #self.optimizer = torch.optim.Adam(self.Transformer.parameters())\n",
    "        self.epoches = 30\n",
    "        self.alpha = 0.7\n",
    "        \n",
    "    def net_PUNN(self, src_inputs, dec_input, target_mask, his_labels):\n",
    "        output_trans = self.PUNN(src_inputs, dec_input, target_mask, his_labels)\n",
    "        return output_trans\n",
    "    \n",
    "    def net_PINN(self, inputs_IDM, his_labels):\n",
    "        output_IDM = self.PINN(inputs_IDM, his_labels)\n",
    "        return output_IDM\n",
    "    \n",
    "    def PINN_without_grad(self, inputs_IDM, his_labels, s_0_item, T_item, a_item, b_item, vd_item):\n",
    "        v_pred = torch.zeros((inputs_IDM.shape[0], self.output_length, 1))\n",
    "        y_pred = torch.zeros((inputs_IDM.shape[0], self.output_length, 1))\n",
    "        acc = torch.zeros((inputs_IDM.shape[0], self.output_length, 1))\n",
    "        y = inputs_IDM[:,0]\n",
    "        v = inputs_IDM[:,1]\n",
    "        s = inputs_IDM[:,2]\n",
    "        delta_v = inputs_IDM[:,3]\n",
    "        \n",
    "        #s_0_item = torch.Tensor(self.s_0.data.cpu().numpy())\n",
    "        #T_item = torch.Tensor(self.T.data.cpu().numpy())\n",
    "        #a_item = torch.Tensor(self.a.data.cpu().numpy())\n",
    "        #b_item = torch.Tensor(self.b.data.cpu().numpy())\n",
    "        #vd_item = torch.Tensor(self.v_d.data.cpu().numpy())\n",
    "        s_x = s_0_item+ torch.max(torch.tensor(0), v*T_item+((v*delta_v)/(2*(a_item*b_item)**0.5)))\n",
    "        #s_x = torch.tensor(2.5)+ torch.max(torch.tensor(0), v*torch.tensor(1.25)+((v*delta_v)/(2*(torch.tensor(1.75)*torch.tensor(1.25))**0.5)))\n",
    "        a_f = a_item*(1-(v/vd_item)**4-(s_x/s)**2)\n",
    "        #a_f = torch.tensor(1.75)*(1-(v/torch.tensor(30))**4-(s_x/s)**2)\n",
    "        v_pred[:,0,0] = v+a_f*self.dt\n",
    "        for i in range(len(v_pred)):\n",
    "            if v_pred[i,0,0]<=0:\n",
    "                v_pred[i,0,0]=0\n",
    "        y_pred[:,0,0] = y+v_pred[i,0,0]*self.dt\n",
    "        acc[:,0,0] = a_f\n",
    "        \n",
    "        for i in range(y_pred.shape[0]):\n",
    "            for j in range(self.output_length-1):\n",
    "                v = v_pred[i,j,0]\n",
    "                delta_v = his_labels[i,j,1]-v_pred[i,j,0]\n",
    "                s = his_labels[i,j,0]-y_pred[i,j,0]\n",
    "                #s_x = self.s_0 + self.T*v - ((v * delta_v)/(2*(self.a*self.b)**0.5))\n",
    "                s_x = s_0_item+  torch.max(torch.tensor(0),v*T_item+((v*delta_v)/(2*(a_item*b_item)**0.5)))\n",
    "                #acc_temp = self.a*(1-(v/self.v_d)**4-(s_x/s)**2)\n",
    "                acc_temp = a_item*(1-(v/vd_item)**4-(s_x/s)**2)\n",
    "                v2 = v + acc_temp * self.dt\n",
    "                if v2 <= 0:\n",
    "                    v2 = 0\n",
    "                    acc_temp = (v2-v)/self.dt\n",
    "                y1 = y_pred[i,j,0]\n",
    "                y2 = y1 + v2 * self.dt\n",
    "                acc[i,j+1,0] = acc_temp\n",
    "                v_pred[i,j+1,0] = v2\n",
    "                y_pred[i,j+1,0] = y2\n",
    "        return y_pred\n",
    "    \n",
    "    def train(self):\n",
    "        #the training part has been deleted because of the confidentiality agreement\n",
    "        \n",
    "    def predict(self, inputs, dec_input, target_mask, his_labels, model_location):\n",
    "        #self.Transformer = TransformerModel(ntokens, ninp, nhead, nhid, nlayers, dropout, fusion_size)\n",
    "        self.PUNN.load_state_dict(torch.load(model_location))\n",
    "        #self.Transformer = model\n",
    "        self.PUNN.eval()\n",
    "        out_Trans = self.net_PUNN(inputs, dec_input, target_mask, his_labels)\n",
    "        #out_IDM = self.net_IDM(inputs[:,-1,:], labels)\n",
    "        return out_Trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "accessible-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_0 = 1.667/(max_num-min_num)\n",
    "T = 0.504\n",
    "a = 0.430/(max_num-min_num)\n",
    "b = 3.216/(max_num-min_num)\n",
    "v_d = 16.775/(max_num-min_num)\n",
    "\n",
    "ntoken = 1 # the size of outputs\n",
    "ninput = 1\n",
    "ninp = 50 # embedding dimension\n",
    "nhid = 50 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 10 # the number of heads in the multiheadattention models\n",
    "fusion_size = 3\n",
    "dropout = 0.1 # the dropout value\n",
    "dt = 0.1\n",
    "output_length = 30\n",
    "\n",
    "PIT_IDM = PINN(s_0, T, a, b, v_d, ninput, ntoken, ninp, nhead, nhid, fusion_size, nlayers, dropout)\n",
    "model_location = r'\\PIT-IDM(2)_UTE.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "federal-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "all_pd_1 = pd.read_csv(r'\\UTE_CKQ4_up.csv', delimiter=',', skiprows=0)\n",
    "all_pd_2 = pd.read_csv(r'\\UTE_CKQ4_down.csv', delimiter=',', skiprows=0)\n",
    "\n",
    "all_pd_data_1 = all_pd_1[['Vehicle_ID', 'Frame_ID', 'y', 'Pre_y', 'v', 'Spacing', 'delta_v', 'Preceding', 'Direction', 'Pre_v']]\n",
    "all_pd_data_2 = all_pd_2[['Vehicle_ID', 'Frame_ID', 'y', 'Pre_y', 'v', 'Spacing', 'delta_v', 'Preceding', 'Direction', 'Pre_v']]\n",
    "all_pd_data = pd.concat([all_pd_data_1, all_pd_data_2], axis=0).reset_index()\n",
    "all_pd_data = all_pd_data.drop(columns=['index'])\n",
    "\n",
    "pro_data = all_pd_data.to_numpy()\n",
    "\n",
    "all_input=[]\n",
    "for i in range(int(0.8*pro_data.shape[0])-2*50):\n",
    "    if pro_data[i, 0] == pro_data[i + 49, 0] and pro_data[i, 7] == pro_data[i + 49, 7] and pro_data[i + 49, 1] - pro_data[\n",
    "        i, 1] == 49*1 and pro_data[i + 49, 0] == pro_data[i + 79, 0] and pro_data[i + 79, 7] == pro_data[i + 49, 7] and pro_data[i + 79, 1] - \\\n",
    "            pro_data[i + 49, 1] == 30*1:\n",
    "        no_use = pro_data[i + 50:i + 2 * 50]\n",
    "        no_use = np.array(no_use)\n",
    "        the_output = no_use[:, :]\n",
    "        all_together = np.hstack((pro_data[i: i + 50][:, :], the_output))\n",
    "        all_input.append(all_together)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "train_labels = []\n",
    "for i in range(len(all_input)):\n",
    "    temp = all_input[i]\n",
    "    temp_y = temp[:30,12]-temp[0,2]\n",
    "    temp_y_pre = temp[:30,13]-temp[0,2]\n",
    "    temp_yv_pre = temp[:30,-1]\n",
    "    #temp_a = temp[:30,-1]\n",
    "    begin_pos = temp[0,2]\n",
    "    temp[:,2] = temp[:,2] - begin_pos\n",
    "    temp[:,3] = temp[:,3] - begin_pos\n",
    "    temp[1:,2] = temp[1:,2]*temp[0,8]\n",
    "    temp[:,3] = temp[:,3]*temp[0,8]\n",
    "    temp_y = temp_y*temp[0,8]\n",
    "    temp_y_pre = temp_y_pre*temp[0,8]\n",
    "    if temp_y[0]<=temp[-1,2] or temp_y[0]<=0 or temp_y[0]>=temp_y_pre[0]:\n",
    "        continue\n",
    "    y_train.append([temp_y])\n",
    "    train_labels.append([temp_y_pre, temp_yv_pre])\n",
    "    x_train.append(temp[:,[2,4,5,6]])\n",
    "\n",
    "all_input=[]\n",
    "for i in range(int(pro_data.shape[0]*0.8), int(pro_data.shape[0]*0.9)-2*50):\n",
    "    if pro_data[i, 0] == pro_data[i + 49, 0] and pro_data[i, 7] == pro_data[i + 49, 7] and pro_data[i + 49, 1] - pro_data[\n",
    "        i, 1] == 49*1 and pro_data[i + 49, 0] == pro_data[i + 79, 0] and pro_data[i + 79, 7] == pro_data[i + 49, 7] and pro_data[i + 79, 1] - \\\n",
    "            pro_data[i + 49, 1] == 30*1:\n",
    "        no_use = pro_data[i + 50:i + 2 * 50]\n",
    "        no_use = np.array(no_use)\n",
    "        the_output = no_use[:, :]\n",
    "        all_together = np.hstack((pro_data[i: i + 50][:, :], the_output))\n",
    "        all_input.append(all_together)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "test_labels = []\n",
    "for i in range(len(all_input)):\n",
    "    temp = all_input[i]\n",
    "    temp_y = temp[:30,12]-temp[0,2]\n",
    "    temp_y_pre = temp[:30,13]-temp[0,2]\n",
    "    temp_yv_pre = temp[:30,-1]\n",
    "    #temp_a = temp[:30,-1]\n",
    "    begin_pos = temp[0,2]\n",
    "    temp[:,2] = temp[:,2] - begin_pos\n",
    "    temp[:,3] = temp[:,3] - begin_pos\n",
    "    temp[1:,2] = temp[1:,2]*temp[0,8]\n",
    "    temp[:,3] = temp[:,3]*temp[0,8]\n",
    "    temp_y = temp_y*temp[0,8]\n",
    "    temp_y_pre = temp_y_pre*temp[0,8]\n",
    "    if temp_y[0]<=temp[-1,2] or temp_y[0]<=0 or temp_y[0]>=temp_y_pre[0]:\n",
    "        continue\n",
    "    y_test.append([temp_y])\n",
    "    test_labels.append([temp_y_pre, temp_yv_pre])\n",
    "    x_test.append(temp[:,[2,4,5,6]])\n",
    "\n",
    "all_input=[]\n",
    "for i in range(int(pro_data.shape[0]*0.9), int(pro_data.shape[0])-2*50):\n",
    "    if pro_data[i, 0] == pro_data[i + 49, 0] and pro_data[i, 7] == pro_data[i + 49, 7] and pro_data[i + 49, 1] - pro_data[\n",
    "        i, 1] == 49*1 and pro_data[i + 49, 0] == pro_data[i + 79, 0] and pro_data[i + 79, 7] == pro_data[i + 49, 7] and pro_data[i + 79, 1] - \\\n",
    "            pro_data[i + 49, 1] == 30*1:\n",
    "        no_use = pro_data[i + 50:i + 2 * 50]\n",
    "        no_use = np.array(no_use)\n",
    "        the_output = no_use[:, :]\n",
    "        all_together = np.hstack((pro_data[i: i + 50][:, :], the_output))\n",
    "        all_input.append(all_together)\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "val_labels = []\n",
    "for i in range(len(all_input)):\n",
    "    temp = all_input[i]\n",
    "    temp_y = temp[:30,12]-temp[0,2]\n",
    "    temp_y_pre = temp[:30,13]-temp[0,2]\n",
    "    temp_yv_pre = temp[:30,-1]\n",
    "    #temp_a = temp[:30,-1]\n",
    "    begin_pos = temp[0,2]\n",
    "    temp[:,2] = temp[:,2] - begin_pos\n",
    "    temp[:,3] = temp[:,3] - begin_pos\n",
    "    temp[1:,2] = temp[1:,2]*temp[0,8]\n",
    "    temp[:,3] = temp[:,3]*temp[0,8]\n",
    "    temp_y = temp_y*temp[0,8]\n",
    "    temp_y_pre = temp_y_pre*temp[0,8]\n",
    "    if temp_y[0]<=temp[-1,2] or temp_y[0]<=0 or temp_y[0]>=temp_y_pre[0]:\n",
    "        continue\n",
    "    y_val.append([temp_y])\n",
    "    val_labels.append([temp_y_pre, temp_yv_pre])\n",
    "    x_val.append(temp[:,[2,4,5,6]])\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "train_labels = np.array(train_labels)\n",
    "y_train = y_train.transpose(0,2,1)\n",
    "train_labels = train_labels.transpose(0,2,1)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "test_labels = np.array(test_labels)\n",
    "y_test = y_test.transpose(0,2,1)\n",
    "test_labels = test_labels.transpose(0,2,1)\n",
    "\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "val_labels = np.array(val_labels)\n",
    "y_val = y_val.transpose(0,2,1)\n",
    "val_labels = val_labels.transpose(0,2,1)\n",
    "\n",
    "max_num = max([np.max(x_train[:,:,0]),np.max(y_train[:,:,0]),np.max(x_test[:,:,0]),np.max(y_test[:,:,0]),np.max(x_val[:,:,0]),np.max(y_val[:,:,0])])\n",
    "min_num = min([np.min(x_train[:,:,0]),np.min(y_train[:,:,0]),np.min(x_test[:,:,0]),np.min(y_test[:,:,0]),np.min(x_val[:,:,0]),np.min(y_val[:,:,0])])\n",
    "\n",
    "x_train[:,:,[0]] = x_train[:,:,[0]]-min_num\n",
    "y_train[:,:,[0]] = y_train[:,:,[0]]-min_num\n",
    "train_labels[:,:,[0]] = train_labels[:,:,[0]]-min_num\n",
    "x_test[:,:,[0]] = x_test[:,:,[0]]-min_num\n",
    "y_test[:,:,[0]] = y_test[:,:,[0]]-min_num\n",
    "test_labels[:,:,[0]] = test_labels[:,:,[0]]-min_num\n",
    "x_val[:,:,[0]] = x_val[:,:,[0]]-min_num\n",
    "y_val[:,:,[0]] = y_val[:,:,[0]]-min_num\n",
    "val_labels[:,:,[0]] = val_labels[:,:,[0]]-min_num\n",
    "\n",
    "x_train = x_train/(max_num-min_num)\n",
    "y_train = y_train/(max_num-min_num)\n",
    "train_labels = train_labels/(max_num-min_num)\n",
    "x_test = x_test/(max_num-min_num)\n",
    "y_test = y_test/(max_num-min_num)\n",
    "test_labels = test_labels/(max_num-min_num)\n",
    "x_val = x_val/(max_num-min_num)\n",
    "y_val = y_val/(max_num-min_num)\n",
    "val_labels = val_labels/(max_num-min_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "disabled-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.1\n",
    "all_input=[]\n",
    "for i in range(int(pro_data.shape[0]*0.8), int(pro_data.shape[0]*0.9)-2*50):\n",
    "    if pro_data[i, 0] == pro_data[i + 49, 0] and pro_data[i, 7] == pro_data[i + 49, 7] and pro_data[i + 49, 1] - pro_data[\n",
    "        i, 1] == 49*1 and pro_data[i + 49, 0] == pro_data[i + 79, 0] and pro_data[i + 79, 7] == pro_data[i + 49, 7] and pro_data[i + 79, 1] - \\\n",
    "            pro_data[i + 49, 1] == 30*1:\n",
    "        no_use = pro_data[i + 50:i + 2 * 50]\n",
    "        no_use = np.array(no_use)\n",
    "        the_output = no_use[:, :]\n",
    "        all_together = np.hstack((pro_data[i: i + 50][:, :], the_output))\n",
    "        all_input.append(all_together)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "test_labels = []\n",
    "test_pre_labels = []\n",
    "begin_positions = []\n",
    "for i in range(len(all_input)):\n",
    "    temp = all_input[i]\n",
    "    temp_y = temp[:30,12]-temp[0,2]\n",
    "    temp_y_pre = temp[:30,13]-temp[0,2]\n",
    "    temp_yv_pre = temp[:30,-1]\n",
    "    #temp_a = temp[:30,-1]\n",
    "    begin_pos = temp[0,2]\n",
    "    temp[:,2] = temp[:,2] - begin_pos\n",
    "    temp[:,3] = temp[:,3] - begin_pos\n",
    "    temp[1:,2] = temp[1:,2]*temp[0,8]\n",
    "    temp[:,3] = temp[:,3]*temp[0,8]\n",
    "    temp_y = temp_y*temp[0,8]\n",
    "    temp_y_pre = temp_y_pre*temp[0,8]\n",
    "    if temp_y[0]<=temp[-1,2] or temp_y[0]<=0 or temp_y[0]>=temp_y_pre[0]:\n",
    "        continue\n",
    "    yv_pre = temp[-1, 9]\n",
    "    y_pre = temp[-1, 3]\n",
    "    if yv_pre != 0:\n",
    "        test_yv_pre = yv_pre*np.ones(30)\n",
    "        test_y_pre = np.linspace(y_pre, y_pre+yv_pre*30*dt,31)[1:]\n",
    "    else:\n",
    "        test_yv_pre = np.zeros(30)\n",
    "        test_y_pre = np.linspace(y_pre, y_pre+temp[-1,4]*30*dt,31)[1:]\n",
    "    y_test.append([temp_y])\n",
    "    test_labels.append([temp_y_pre, temp_yv_pre])\n",
    "    x_test.append(temp[:,[2,4,5,6]])\n",
    "    test_pre_labels.append([test_y_pre, test_yv_pre])\n",
    "    begin_positions.append(begin_pos)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "test_labels = np.array(test_labels)\n",
    "test_pre_labels = np.array(test_pre_labels)\n",
    "y_test = y_test.transpose(0,2,1)\n",
    "test_labels = test_labels.transpose(0,2,1)\n",
    "test_pre_labels = test_pre_labels.transpose(0,2,1)\n",
    "\n",
    "x_test[:,:,[0]] = x_test[:,:,[0]]-min_num\n",
    "y_test[:,:,[0]] = y_test[:,:,[0]]-min_num\n",
    "test_labels[:,:,[0]] = test_labels[:,:,[0]]-min_num\n",
    "test_pre_labels[:,:,[0]] = test_pre_labels[:,:,[0]]-min_num\n",
    "\n",
    "x_test = x_test/(max_num-min_num)\n",
    "y_test = y_test/(max_num-min_num)\n",
    "test_labels = test_labels/(max_num-min_num)\n",
    "test_pre_labels = test_pre_labels/(max_num-min_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "random-possession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13967, 50, 4) (13967, 30, 1) (13967, 30, 2) 13967\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape, y_test.shape, test_pre_labels.shape, len(begin_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dedicated-chorus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from multi_attention_forward import multi_head_attention_forward\n",
    "\n",
    "def _get_activation_fn(activation):\n",
    "    if activation == \"relu\":\n",
    "        return F.relu\n",
    "    elif activation == \"gelu\":\n",
    "        return F.gelu\n",
    "    else:\n",
    "        raise RuntimeError(\"activation should be relu/gelu, not %s.\" % activation)\n",
    "\n",
    "def _get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"\"\"\n",
    "    Mask out subsequent positions.\n",
    "    \"\"\"\n",
    "    attn_shape = (1, size, size)\n",
    "    mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(mask) == 0\n",
    "\n",
    "def _generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()       \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        #pe.requires_grad = False\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "    r\"\"\"Allows the model to jointly attend to information\n",
    "    from different representation subspaces.\n",
    "    See reference: Attention Is All You Need\n",
    "    .. math::\n",
    "        \\text{MultiHead}(Q, K, V) = \\text{Concat}(head_1,\\dots,head_h)W^O\n",
    "        \\text{where} head_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n",
    "    Args:\n",
    "        embed_dim: total dimension of the model.\n",
    "        num_heads: parallel attention heads.\n",
    "        dropout: a Dropout layer on attn_output_weights. Default: 0.0.\n",
    "        bias: add bias as module parameter. Default: True.\n",
    "        add_bias_kv: add bias to the key and value sequences at dim=0.\n",
    "        add_zero_attn: add a new batch of zeros to the key and\n",
    "                       value sequences at dim=1.\n",
    "        kdim: total number of features in key. Default: None.\n",
    "        vdim: total number of features in key. Default: None.\n",
    "        Note: if kdim and vdim are None, they will be set to embed_dim such that\n",
    "        query, key, and value have the same number of features.\n",
    "    Examples::\n",
    "        >>> multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        >>> attn_output, attn_output_weights = multihead_attn(query, key, value)\n",
    "    \"\"\"\n",
    "    __constants__ = ['q_proj_weight', 'k_proj_weight', 'v_proj_weight', 'in_proj_weight']\n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0., bias=True, add_bias_kv=False, add_zero_attn=False, kdim=None,\n",
    "                 vdim=None):\n",
    "        super(MultiheadAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.kdim = kdim if kdim is not None else embed_dim\n",
    "        self.vdim = vdim if vdim is not None else embed_dim\n",
    "        self._qkv_same_embed_dim = self.kdim == embed_dim and self.vdim == embed_dim\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        assert self.head_dim * num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n",
    "\n",
    "        if self._qkv_same_embed_dim is False:\n",
    "            self.q_proj_weight = nn.Parameter(torch.Tensor(embed_dim, embed_dim))\n",
    "            self.k_proj_weight = nn.Parameter(torch.Tensor(embed_dim, self.kdim))\n",
    "            self.v_proj_weight = nn.Parameter(torch.Tensor(embed_dim, self.vdim))\n",
    "            self.register_parameter('in_proj_weight', None)\n",
    "        else:\n",
    "            self.in_proj_weight = nn.Parameter(torch.empty(3 * embed_dim, embed_dim))\n",
    "            self.register_parameter('q_proj_weight', None)\n",
    "            self.register_parameter('k_proj_weight', None)\n",
    "            self.register_parameter('v_proj_weight', None)\n",
    "\n",
    "        if bias:\n",
    "            self.in_proj_bias = nn.Parameter(torch.empty(3 * embed_dim))\n",
    "        else:\n",
    "            self.register_parameter('in_proj_bias', None)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
    "\n",
    "        if add_bias_kv:\n",
    "            self.bias_k = nn.Parameter(torch.empty(1, 1, embed_dim))\n",
    "            self.bias_v = nn.Parameter(torch.empty(1, 1, embed_dim))\n",
    "        else:\n",
    "            self.bias_k = self.bias_v = None\n",
    "\n",
    "        self.add_zero_attn = add_zero_attn\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        if self._qkv_same_embed_dim:\n",
    "            nn.init.xavier_uniform_(self.in_proj_weight)\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(self.q_proj_weight)\n",
    "            nn.init.xavier_uniform_(self.k_proj_weight)\n",
    "            nn.init.xavier_uniform_(self.v_proj_weight)\n",
    "\n",
    "        if self.in_proj_bias is not None:\n",
    "            nn.init.constant_(self.in_proj_bias, 0.)\n",
    "            nn.init.constant_(self.out_proj.bias, 0.)\n",
    "        if self.bias_k is not None:\n",
    "            nn.init.xavier_normal_(self.bias_k)\n",
    "        if self.bias_v is not None:\n",
    "            nn.init.xavier_normal_(self.bias_v)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        # Support loading old MultiheadAttention checkpoints generated by v1.1.0\n",
    "        if '_qkv_same_embed_dim' not in state:\n",
    "            state['_qkv_same_embed_dim'] = True\n",
    "\n",
    "        super(MultiheadAttention, self).__setstate__(state)\n",
    "\n",
    "    def forward(self, query, key, value, key_padding_mask=None,\n",
    "                need_weights=True, attn_mask=None):\n",
    "        # type: (Tensor, Tensor, Tensor, Optional[Tensor], bool, Optional[Tensor]) -> Tuple[Tensor, Optional[Tensor]]\n",
    "        r\"\"\"\n",
    "    Args:\n",
    "        query, key, value: map a query and a set of key-value pairs to an output.\n",
    "            See \"Attention Is All You Need\" for more details.\n",
    "        key_padding_mask: if provided, specified padding elements in the key will\n",
    "            be ignored by the attention. This is an binary mask. When the value is True,\n",
    "            the corresponding value on the attention layer will be filled with -inf.\n",
    "        need_weights: output attn_output_weights.\n",
    "        attn_mask: mask that prevents attention to certain positions. This is an additive mask\n",
    "            (i.e. the values will be added to the attention layer).\n",
    "    Shape:\n",
    "        - Inputs:\n",
    "        - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is\n",
    "          the embedding dimension.\n",
    "        - key: :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is\n",
    "          the embedding dimension.\n",
    "        - value: :math:`(S, N, E)` where S is the source sequence length, N is the batch size, E is\n",
    "          the embedding dimension.\n",
    "        - key_padding_mask: :math:`(N, S)`, ByteTensor, where N is the batch size, S is the source sequence length.\n",
    "        - attn_mask: :math:`(L, S)` where L is the target sequence length, S is the source sequence length.\n",
    "        - Outputs:\n",
    "        - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,\n",
    "          E is the embedding dimension.\n",
    "        - attn_output_weights: :math:`(N, L, S)` where N is the batch size,\n",
    "          L is the target sequence length, S is the source sequence length.\n",
    "        \"\"\"\n",
    "        if not self._qkv_same_embed_dim:\n",
    "            return multi_head_attention_forward(\n",
    "                query, key, value, self.embed_dim, self.num_heads,\n",
    "                self.in_proj_weight, self.in_proj_bias,\n",
    "                self.bias_k, self.bias_v, self.add_zero_attn,\n",
    "                self.dropout, self.out_proj.weight, self.out_proj.bias,\n",
    "                training=self.training,\n",
    "                key_padding_mask=key_padding_mask, need_weights=need_weights,\n",
    "                attn_mask=attn_mask, use_separate_proj_weight=True,\n",
    "                q_proj_weight=self.q_proj_weight, k_proj_weight=self.k_proj_weight,\n",
    "                v_proj_weight=self.v_proj_weight)\n",
    "        else:\n",
    "            return multi_head_attention_forward(\n",
    "                query, key, value, self.embed_dim, self.num_heads,\n",
    "                self.in_proj_weight, self.in_proj_bias,\n",
    "                self.bias_k, self.bias_v, self.add_zero_attn,\n",
    "                self.dropout, self.out_proj.weight, self.out_proj.bias,\n",
    "                training=self.training,\n",
    "                key_padding_mask=key_padding_mask, need_weights=need_weights,\n",
    "                attn_mask=attn_mask)\n",
    "\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0, activation=\"relu\"):\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        r\"\"\"Pass the input through the encoder layer.\n",
    "\n",
    "        Args:\n",
    "            src: the sequnce to the encoder layer (required).\n",
    "            src_mask: the mask for the src sequence (optional).\n",
    "            src_key_padding_mask: the mask for the src keys per batch (optional).\n",
    "\n",
    "        Shape:\n",
    "            see the docs in Transformer class.\n",
    "        \"\"\"\n",
    "        src2, attn = self.self_attn(src, src, src, attn_mask=src_mask,\n",
    "                                    key_padding_mask=src_key_padding_mask)\n",
    "        src = src + self.dropout1(src2)\n",
    "        src = self.norm1(src)\n",
    "\n",
    "        if hasattr(self, \"activation\"):\n",
    "            src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        else:  # for backward compatibility\n",
    "            src2 = self.linear2(self.dropout(F.relu(self.linear1(src))))\n",
    "\n",
    "        src = src + self.dropout2(src2)\n",
    "        src = self.norm2(src)\n",
    "        return src, attn\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    r\"\"\"TransformerEncoder is a stack of N encoder layers\n",
    "\n",
    "    Args:\n",
    "        encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n",
    "        num_layers: the number of sub-encoder-layers in the encoder (required).\n",
    "        norm: the layer normalization component (optional).\n",
    "\n",
    "    Examples::\n",
    "        >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        >>> transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "        >>> src = torch.rand(10, 32, 512)\n",
    "        >>> out = transformer_encoder(src)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder_layer, num_layers, norm=None):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.layers = _get_clones(encoder_layer, num_layers)\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, src, mask=None, src_key_padding_mask=None):\n",
    "        r\"\"\"Pass the input through the encoder layers in turn.\n",
    "\n",
    "        Args:\n",
    "            src: the sequnce to the encoder (required).\n",
    "            mask: the mask for the src sequence (optional).\n",
    "            src_key_padding_mask: the mask for the src keys per batch (optional).\n",
    "\n",
    "        Shape:\n",
    "            see the docs in Transformer class.\n",
    "        \"\"\"\n",
    "        output = src\n",
    "\n",
    "        atts = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            output, attn = self.layers[i](output, src_mask=mask,\n",
    "                                          src_key_padding_mask=src_key_padding_mask)\n",
    "            atts.append(attn)\n",
    "        if self.norm:\n",
    "            output = self.norm(output)\n",
    "\n",
    "        return output, atts\n",
    "\n",
    "class TransformerDecoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0, activation=\"relu\"):\n",
    "        super(TransformerDecoderLayer, self).__init__()\n",
    "        self.tgt_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.src_attn = MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "\n",
    "    def forward(self, src, target, src_mask=None, target_mask=None, src_key_padding_mask=None):\n",
    "        r\"\"\"Pass the input through the encoder layer.\n",
    "\n",
    "        Args:\n",
    "            src: the sequnce to the encoder layer (required).\n",
    "            src_mask: the mask for the src sequence (optional).\n",
    "            src_key_padding_mask: the mask for the src keys per batch (optional).\n",
    "\n",
    "        Shape:\n",
    "            see the docs in Transformer class.\n",
    "        \"\"\"\n",
    "        target2, attn_tgt = self.tgt_attn(target, target, target, attn_mask=target_mask,\n",
    "                                    key_padding_mask=src_key_padding_mask)\n",
    "        target = target+self.dropout1(target2)\n",
    "        target = self.norm1(target)\n",
    "        \n",
    "        target2, attn_src = self.src_attn(target, src, src, attn_mask=src_mask,\n",
    "                                    key_padding_mask=src_key_padding_mask)\n",
    "        target = target + self.dropout2(target2)\n",
    "        target = self.norm2(target)\n",
    "\n",
    "        if hasattr(self, \"activation\"):\n",
    "            target2 = self.linear2(self.dropout(self.activation(self.linear1(target))))\n",
    "        else:  # for backward compatibility\n",
    "            target2 = self.linear2(self.dropout(F.relu(self.linear1(target))))\n",
    "\n",
    "        target = target + self.dropout3(target2)\n",
    "        target = self.norm3(target)\n",
    "        return target, attn_tgt, attn_src\n",
    "    \n",
    "class TransformerDecoder(nn.Module):\n",
    "    r\"\"\"TransformerEncoder is a stack of N encoder layers\n",
    "\n",
    "    Args:\n",
    "        encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n",
    "        num_layers: the number of sub-encoder-layers in the encoder (required).\n",
    "        norm: the layer normalization component (optional).\n",
    "\n",
    "    Examples::\n",
    "        >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        >>> transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "        >>> src = torch.rand(10, 32, 512)\n",
    "        >>> out = transformer_encoder(src)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, decoder_layer, num_layers, norm=None):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.layers = _get_clones(decoder_layer, num_layers)\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "\n",
    "    def forward(self, src, target, src_mask=None, target_mask=None, src_key_padding_mask=None):\n",
    "        r\"\"\"Pass the input through the encoder layers in turn.\n",
    "\n",
    "        Args:\n",
    "            src: the sequnce to the encoder (required).\n",
    "            mask: the mask for the src sequence (optional).\n",
    "            src_key_padding_mask: the mask for the src keys per batch (optional).\n",
    "\n",
    "        Shape:\n",
    "            see the docs in Transformer class.\n",
    "        \"\"\"\n",
    "\n",
    "        atts_tgt = []\n",
    "        atts_src = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            target, attn_tgt, attn_src = self.layers[i](src, target, src_mask=src_mask,target_mask = target_mask,\n",
    "                                          src_key_padding_mask=src_key_padding_mask)\n",
    "            atts_tgt.append(attn_tgt)\n",
    "            atts_src.append(attn_src)\n",
    "        if self.norm:\n",
    "            target = self.norm(target)\n",
    "\n",
    "        return target, atts_tgt, atts_src\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ninput, ntoken, ninp, nhead, nhid, nlayers, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.src_mask = None\n",
    "        self.encoder_pos = PositionalEncoding(ninp)\n",
    "        self.encoder_emb = nn.Linear(ninput, ninp)\n",
    "        self.encoder_layer = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.encoder = TransformerEncoder(self.encoder_layer, nlayers)\n",
    "        self.decoder_emb = nn.Linear(ninput, ninp)\n",
    "        self.decoder_layer = TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.decoder = TransformerDecoder(self.decoder_layer, nlayers)\n",
    "        self.output_layer = nn.Linear(ninp, ntoken)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1    \n",
    "        self.encoder_emb.bias.data.zero_()\n",
    "        self.encoder_emb.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder_emb.bias.data.zero_()\n",
    "        self.decoder_emb.weight.data.uniform_(-initrange, initrange)\n",
    "        self.output_layer.bias.data.zero_()\n",
    "        self.output_layer.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, inputs, dec_input, target_mask):\n",
    "        #inputs = src_inputs[:,:,[0]]\n",
    "        src = self.encoder_pos(self.encoder_emb(inputs.transpose(0,1)))\n",
    "        memory, attention_enc = self.encoder(src)\n",
    "        inp_decoder = self.decoder_emb(dec_input.transpose(0,1))\n",
    "        out_decoder, attention_tgt, attention_src = self.decoder(src=memory, target=inp_decoder, src_mask=None, target_mask=target_mask)\n",
    "        output = self.output_layer(out_decoder)\n",
    "        output = output.transpose(0,1)\n",
    "        return output, attention_enc, attention_tgt, attention_src\n",
    "\n",
    "ninp = 50\n",
    "ninput = 1\n",
    "ntoken = 1\n",
    "nhid = 50\n",
    "nhead = 10\n",
    "dropout = 0.1\n",
    "nlayers = 2\n",
    "Trans_model = TransformerModel(ninput, ntoken, ninp, nhead, nhid, nlayers, dropout)\n",
    "Trans_model_location = r'\\Transformer_UTE.tar'\n",
    "Trans_model.load_state_dict(torch.load(Trans_model_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "careful-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "portable-burning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13967, 50, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pointed-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_item = 2.681\n",
    "b_item = 5.485\n",
    "v_d_item = 34.569\n",
    "s_0_item = 5.872\n",
    "T_item = 1.191\n",
    "dt = 0.1\n",
    "def model_IDM_test(inputs_IDM, his_labels, output_length):\n",
    "    v_pred = torch.zeros((inputs_IDM.shape[0], output_length, 1))\n",
    "    y_pred = torch.zeros((inputs_IDM.shape[0], output_length, 1))\n",
    "    acc = torch.zeros((inputs_IDM.shape[0], output_length, 1))\n",
    "    y = inputs_IDM[:,0]\n",
    "    v = inputs_IDM[:,1]\n",
    "    s = inputs_IDM[:,2]\n",
    "    delta_v = inputs_IDM[:,3]\n",
    "    \n",
    "    s_x = s_0_item + torch.max(torch.tensor(0), v*T_item+((v*delta_v)/(2*(a_item*b_item)**0.5)))\n",
    "    #s_x = torch.tensor(2.5)+ torch.max(torch.tensor(0), v*torch.tensor(1.25)+((v*delta_v)/(2*(torch.tensor(1.75)*torch.tensor(1.25))**0.5)))\n",
    "    a_f = a_item*(1-(v/v_d_item)**4-(s_x/s)**2)\n",
    "    #a_f = torch.tensor(1.75)*(1-(v/torch.tensor(30))**4-(s_x/s)**2)\n",
    "    v_pred[:,0,0] = v+a_f*dt\n",
    "    for i in range(len(v_pred)):\n",
    "        if v_pred[i,0,0]<=0:\n",
    "            v_pred[i,0,0]=0\n",
    "    y_pred[:,0,0] = y+v_pred[i,0,0]*dt\n",
    "    acc[:,0,0] = a_f\n",
    "        \n",
    "    for i in range(y_pred.shape[0]):\n",
    "        for j in range(output_length-1):\n",
    "            v = v_pred[i,j,0]\n",
    "            delta_v = his_labels[i,j,1]-v_pred[i,j,0]\n",
    "            s = his_labels[i,j,0]-y_pred[i,j,0]\n",
    "            #s_x = self.s_0 + self.T*v - ((v * delta_v)/(2*(self.a*self.b)**0.5))\n",
    "            #s_x = s_0 +  v*T-((v*delta_v)/(2*(a*b)**0.5))\n",
    "            s_x = s_0_item +  torch.max(torch.tensor(0), v*T_item+((v*delta_v)/(2*(a_item*b_item)**0.5)))\n",
    "            #acc_temp = self.a*(1-(v/self.v_d)**4-(s_x/s)**2)\n",
    "            acc_temp = a_item*(1-(v/v_d_item)**4-(s_x/s)**2)\n",
    "            v2 = v + acc_temp * dt\n",
    "            if v2<=0:\n",
    "                v2 = 0\n",
    "                acc_temp = (v2-v)/dt\n",
    "            y1 = y_pred[i,j,0]\n",
    "            y2 = y1 + v2 * dt\n",
    "            acc[i,j+1,0] = acc_temp\n",
    "            v_pred[i,j+1,0] = v2\n",
    "            y_pred[i,j+1,0] = y2\n",
    "                   \n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "meaning-message",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1,ax2)=plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "\n",
    "i = 32\n",
    "inputs = torch.from_numpy(x_test[20*i+5,:,:]).unsqueeze(0).to(torch.float32)\n",
    "hist_labels = torch.from_numpy(test_pre_labels[20*i+5,:,:]).unsqueeze(0).to(torch.float32)\n",
    "labels = torch.from_numpy(y_test[20*i+5,:,:]).unsqueeze(0).to(torch.float32)\n",
    "\n",
    "inputs_trans = inputs[:,:,[0]]\n",
    "start_of_seq = torch.Tensor([0]).unsqueeze(0).unsqueeze(1).repeat(labels.shape[0],1,1)\n",
    "dec_input = start_of_seq\n",
    "for j in range(output_length):\n",
    "    target_mask = _generate_square_subsequent_mask(dec_input.shape[1])\n",
    "    output_trans,_,_,_ = Trans_model(inputs_trans, dec_input, target_mask)\n",
    "    dec_input = torch.cat((dec_input, output_trans[:,-1:,:]),1)\n",
    "outputs_trans = dec_input[:,1:,:]\n",
    "\n",
    "start_of_seq = torch.Tensor([0]).unsqueeze(0).unsqueeze(1).repeat(labels.shape[0],1,1)\n",
    "dec_input = start_of_seq\n",
    "for j in range(output_length):\n",
    "    target_mask = _generate_square_subsequent_mask(dec_input.shape[1])\n",
    "    outputs = PIT_IDM.predict(inputs, dec_input, target_mask, hist_labels, model_location)\n",
    "    dec_input = torch.cat((dec_input, outputs[:,-1:,:]),1)\n",
    "outputs = dec_input[:,1:,:]\n",
    "\n",
    "outputs_IDM = model_IDM(inputs[:,-1,:], hist_labels[:,:,:], output_length)\n",
    "y_label = labels[0,:,0].detach().numpy()*(max_num-min_num)\n",
    "y_output = outputs[0,:,0].detach().numpy()*(max_num-min_num)\n",
    "y_output_IDM = outputs_IDM[0,:,0].detach().numpy()*(max_num-min_num)\n",
    "y_output_trans = outputs_trans[0,:,0].detach().numpy()*(max_num-min_num)\n",
    "x_pred = np.arange(1,32)+49\n",
    "x_obs = np.arange(1,51)\n",
    "y_obs = inputs[0,:,0].detach().numpy()*(max_num-min_num)\n",
    "y_label = np.concatenate((np.array([y_obs[-1]]),y_label))\n",
    "y_output= np.concatenate((np.array([y_obs[-1]]),y_output))\n",
    "y_output_IDM = np.concatenate((np.array([y_obs[-1]]),y_output_IDM))\n",
    "y_output_trans = np.concatenate((np.array([y_obs[-1]]),y_output_trans))\n",
    "\n",
    "ax1.plot(x_obs[40:], (y_obs[40:]+min_num+begin_positions[40*i+17]), color='black', label='Ground truth')\n",
    "ax1.plot(x_pred, (y_label+min_num+begin_positions[40*i+17]), color='red', label='Observation')\n",
    "ax1.plot(x_pred, (y_output+min_num+begin_positions[40*i+17]), color='blue', label='PIT-IDM')\n",
    "ax1.plot(x_pred, (y_output_IDM+min_num+begin_positions[40*i+17]), color='orange', label='IDM')\n",
    "ax1.plot(x_pred, (y_output_trans+min_num+begin_positions[40*i+17]), color='green', label='Transformer')\n",
    "ax1.set_xlabel('Time Steps', fontdict={'size':15})\n",
    "ax1.set_ylabel('Position (m)', fontdict={'size':15})\n",
    "ax1.tick_params(axis='x', labelsize=15)\n",
    "ax1.tick_params(axis='y', labelsize=15)\n",
    "ax1.legend(prop={'size':12})\n",
    "\n",
    "i = 67\n",
    "inputs = torch.from_numpy(x_test[30*i+5,:,:]).unsqueeze(0).to(torch.float32)\n",
    "hist_labels = torch.from_numpy(test_pre_labels[30*i+5,:,:]).unsqueeze(0).to(torch.float32)\n",
    "labels = torch.from_numpy(y_test[30*i+5,:,:]).unsqueeze(0).to(torch.float32)\n",
    "\n",
    "inputs_trans = inputs[:,:,[0]]\n",
    "start_of_seq = torch.Tensor([0]).unsqueeze(0).unsqueeze(1).repeat(labels.shape[0],1,1)\n",
    "dec_input = start_of_seq\n",
    "for j in range(output_length):\n",
    "    target_mask = _generate_square_subsequent_mask(dec_input.shape[1])\n",
    "    output_trans,_,_,_ = Trans_model(inputs_trans, dec_input, target_mask)\n",
    "    dec_input = torch.cat((dec_input, output_trans[:,-1:,:]),1)\n",
    "outputs_trans = dec_input[:,1:,:]\n",
    "\n",
    "start_of_seq = torch.Tensor([0]).unsqueeze(0).unsqueeze(1).repeat(labels.shape[0],1,1)\n",
    "dec_input = start_of_seq\n",
    "for j in range(output_length):\n",
    "    target_mask = _generate_square_subsequent_mask(dec_input.shape[1])\n",
    "    outputs = PIT_IDM.predict(inputs, dec_input, target_mask, hist_labels, model_location)\n",
    "    dec_input = torch.cat((dec_input, outputs[:,-1:,:]),1)\n",
    "outputs = dec_input[:,1:,:]\n",
    "\n",
    "outputs_IDM = model_IDM(inputs[:,-1,:], hist_labels[:,:,:], output_length)\n",
    "y_label = labels[0,:,0].detach().numpy()*(max_num-min_num)\n",
    "y_output = outputs[0,:,0].detach().numpy()*(max_num-min_num)\n",
    "y_output_IDM = outputs_IDM[0,:,0].detach().numpy()*(max_num-min_num)\n",
    "y_output_trans = outputs_trans[0,:,0].detach().numpy()*(max_num-min_num)\n",
    "x_pred = np.arange(1,32)+49\n",
    "x_obs = np.arange(1,51)\n",
    "y_obs = inputs[0,:,0].detach().numpy()*(max_num-min_num)\n",
    "y_label = np.concatenate((np.array([y_obs[-1]]),y_label))\n",
    "y_output= np.concatenate((np.array([y_obs[-1]]),y_output))\n",
    "y_output_IDM = np.concatenate((np.array([y_obs[-1]]),y_output_IDM))\n",
    "y_output_trans = np.concatenate((np.array([y_obs[-1]]),y_output_trans))\n",
    "\n",
    "ax2.plot(x_obs[40:], (y_obs[40:]+min_num+begin_positions[30*i+5]), color='black', label='Ground truth')\n",
    "ax2.plot(x_pred, (y_label+min_num+begin_positions[30*i+5]), color='red', label='Observation')\n",
    "ax2.plot(x_pred, (y_output+min_num+begin_positions[30*i+5]), color='blue', label='PIT-IDM')\n",
    "ax2.plot(x_pred, (y_output_IDM+min_num+begin_positions[30*i+5]), color='orange', label='IDM')\n",
    "ax2.plot(x_pred, (y_output_trans+min_num+begin_positions[30*i+5]), color='green', label='Transformer')\n",
    "ax2.set_xlabel('Time Steps', fontdict={'size':15})\n",
    "ax2.set_ylabel('Position (m)', fontdict={'size':15})\n",
    "ax2.tick_params(axis='x', labelsize=15)\n",
    "ax2.tick_params(axis='y', labelsize=15)\n",
    "ax2.legend(prop={'size':12})\n",
    "\n",
    "fig.savefig(r'\\single_UTE_all.svg',format='svg',dpi=600,bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-water",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-gateway",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
